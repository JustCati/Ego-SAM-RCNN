# SAMMask - Object Detection and Segmentation with Mask-RCNN and Segment Anything Model (SAM) for Mask Generation

## Overview

This project implements Mask-RCNN for object detection and instance segmentation using masks generated by the Segment Anything Model (SAM). The project is designed to work with the COCO-O dataset, a variant of the COCO dataset that introduces out-of-distribution (OOD) scenarios, testing the robustness of modern object detectors.

## Features

- **Mask-RCNN**: Utilizes the ResNet50-FPN V2 backbone for object detection and instance segmentation.
- **Segment Anything Model (SAM)**: Employed to generate segmentation masks for bounding boxes in the COCO-O dataset.
- **COCO-O Dataset Compatibility**: Specifically designed to handle the challenges posed by the COCO-O dataset, which includes diverse and difficult image contexts such as weather, sketch, and cartoon.

## Setup and Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/JustCati/SamMask-R-CNN.git
   cd SamMask-R-CNN
   ```

2. **Install the required dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Download the COCO-O dataset**:
   - The dataset used in this project is COCO-O, which can be found [here](https://arxiv.org/abs/XXXXXX).
   - Place the dataset in the `data/` directory.

## Results

- **mAP**: The best model achieved a mean Average Precision (mAP) of 32.9% for bounding boxes and 9.3% for segmentation masks.
- **mAR**: The mean Average Recall (mAR) achieved was 38.7% for bounding boxes and 32.7% for segmentation masks.
- **Performance Insights**: The generated masks from SAM are generally accurate, especially for well-defined objects. However, performance may degrade with large or overlapping bounding boxes.

## Implemented Solutions

- **GPU Memory Limitations**: Training Mask-RCNN with a batch size greater than 1 may result in out-of-memory errors on GPUs with less than 8GB of VRAM. To address this:
  - Use of `torch.cuda.empty_cache()` to free up unused GPU memory during training.
  - Implemented batch skipping to avoid out-of-memory errors during the initial epochs where the number of predicted bounding boxes is high.

## Known Issues

- **Low mAP for Segmentation**: The low mean Average Precision (mAP) for segmentation is primarily due to the lack of a single confidence score for each mask. The current implementation uses an average of pixel-level confidence scores, which may not accurately reflect the model's true performance. Efforts to improve this calculation are ongoing.

## Acknowledgements

- The implementation of Mask-RCNN is based on the [PyTorch Mask R-CNN example](https://pytorch.org/vision/stable/models/generated/torchvision.models.detection.maskrcnn_resnet50_fpn_v2.html#torchvision.models.detection.maskrcnn_resnet50_fpn_v2).
- The SAM model was inspired by the Segment Anything Model described in [this paper](https://arxiv.org/abs/XXXXXX).

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
